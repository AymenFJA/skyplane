{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format = 'svg'\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from skylark import skylark_root, MB, GB\n",
    "from skylark.gateway.chunk import ChunkState\n",
    "\n",
    "base_dir = skylark_root / \"data\" / \"experiments\" / \"benchmark_triangles\"\n",
    "fig_dir = base_dir / \"figures\" / \"benchmark_triangles\" / datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "fig_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = list((base_dir / \"logs\").glob(\"*\"))\n",
    "\n",
    "rows = []\n",
    "for config in configs:\n",
    "    for f in (skylark_root / \"data\" / \"experiments\" / \"benchmark_triangles\" / config / \"results\").glob(\"*.pkl\"):\n",
    "        with open(f, \"rb\") as fp:\n",
    "            result = pickle.load(fp)\n",
    "        rows.append(result)\n",
    "df = pd.DataFrame(rows)\n",
    "df_orig = df.copy()\n",
    "\n",
    "if \"error\" in df.columns:\n",
    "    for row in df[df.error.notnull()].itertuples():\n",
    "        print(f\"{row.src_region} -> {row.dst_region} -> {row.inter_region}: {row.error}\")\n",
    "    df = df[df.error.isnull()]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for (src, dst), group_df in df.groupby([\"src_region\", \"dst_region\"]):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "        group_df = group_df[(group_df.inter_region != src) & (group_df.inter_region != dst)]\n",
    "\n",
    "        # sort by throughput_gbits\n",
    "        group_df = group_df.sort_values(by=\"throughput_gbits\", ascending=True)\n",
    "        group_df[\"inter_region\"] = group_df.inter_region.fillna(\"Direct\")\n",
    "        group_df[\"label\"] = group_df.apply(lambda row: f\"{row.inter_region} ({row.num_gateways} x {row.num_outgoing_connections})\", axis=1)\n",
    "        group_df[\"transfer_bytes\"] = group_df.apply(lambda row: row.n_chunks * row.chunk_size_mb * MB, axis=1)\n",
    "        assert np.all(group_df.transfer_bytes == group_df.transfer_bytes[0])\n",
    "\n",
    "        # plot barh\n",
    "        # title = f\"Skylark throughput {src} => {dst}, {group_df.transfer_bytes[0] / GB:.2f}GB in group_df.num_chunks[0]x group_df.chunk_size_mb[0]MB chunks\"\n",
    "        with plt.style.context([\"seaborn-white\", {\"font.size\": 10}]):\n",
    "            fig, ax = plt.subplots(figsize=(8, 6))\n",
    "            ax.barh(\n",
    "                group_df.label,\n",
    "                group_df.throughput_gbits,\n",
    "            )\n",
    "            ax.set_xlabel(\"Throughput (Gbps)\")\n",
    "            ax.set_ylabel(\"Inter-region relay\")\n",
    "            ax.set_title(f\"{src} => {dst}, {group_df.transfer_bytes[0] / GB:.2f}GB ({group_df.n_chunks[0]}x{group_df.chunk_size_mb[0]}MB)\")\n",
    "\n",
    "            # add white labels to each bar\n",
    "            for i, (label, throughput) in enumerate(zip(group_df.label, group_df.throughput_gbits)):\n",
    "                # assert i, throughput not NaN\n",
    "                if not np.isnan(throughput):\n",
    "                    ax.text(\n",
    "                        throughput,\n",
    "                        i,\n",
    "                        f\"{throughput:.2f} Gbps \",\n",
    "                        ha=\"right\",\n",
    "                        va=\"center\",\n",
    "                        color=\"white\",\n",
    "                    )\n",
    "\n",
    "            # save plots\n",
    "            fig.tight_layout()\n",
    "            fig.savefig(fig_dir / f\"{src}_{dst}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "            fig.savefig(fig_dir / f\"{src}_{dst}.pdf\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorized version\n",
    "def compute_throughput_df(df_log, chunk_size_bytes):\n",
    "    df_log = df_log.reset_index(drop=True).set_index([\"path_idx\", \"hop_idx\", \"chunk_id\", \"state\"]).sort_index()\n",
    "    unstacked_time = df_log.time.unstack(level=3)\n",
    "    unstacked_time.columns = [f\"{col.name}_time\" for col in unstacked_time.columns]\n",
    "    unstacked_time[\"runtime_upload\"] = (\n",
    "        unstacked_time[\"upload_complete_time\"] - unstacked_time[\"upload_in_progress_time\"]\n",
    "    ).dt.total_seconds()\n",
    "    unstacked_time[\"runtime_download\"] = (\n",
    "        unstacked_time[\"downloaded_time\"] - unstacked_time[\"download_in_progress_time\"]\n",
    "    ).dt.total_seconds()\n",
    "    unstacked_time[\"runtime_queue\"] = (unstacked_time[\"upload_in_progress_time\"] - unstacked_time[\"upload_queued_time\"]).dt.total_seconds()\n",
    "    unstacked_time[\"runtime_total\"] = (unstacked_time[\"upload_complete_time\"] - unstacked_time[\"registered_time\"]).dt.total_seconds()\n",
    "    unstacked_time[\"upload_gbits\"] = (chunk_size_bytes / GB * 8) / unstacked_time[\"runtime_upload\"]\n",
    "    unstacked_time[\"download_gbits\"] = (chunk_size_bytes / GB * 8) / unstacked_time[\"runtime_download\"]\n",
    "    return unstacked_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot grid of subplots\n",
    "grouped = df.groupby([\"src_region\", \"dst_region\"])\n",
    "n_rows = len(grouped.groups)\n",
    "n_cols = max(len(grouped.get_group(group).inter_region.unique()) for group in grouped.groups)\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 4))\n",
    "with tqdm(total=n_rows * n_cols) as pbar:\n",
    "    for plot_row_idx, ((src_region, dst_region), df_row) in enumerate(grouped):\n",
    "        # set subplots row labels on left of plot\n",
    "        df_row[\"inter_region\"] = df_row.inter_region.fillna(\"Direct\")\n",
    "        axs[plot_row_idx, 0].set_ylabel(f\"{src_region} => {dst_region}\")\n",
    "        for plot_col_idx, (inter_region, df_plot) in enumerate(df_row.groupby(\"inter_region\")):\n",
    "            if plot_row_idx == 0:\n",
    "                axs[plot_row_idx, plot_col_idx].set_title(f\"Relay: {inter_region}\")\n",
    "            ax = axs[plot_row_idx, plot_col_idx]\n",
    "            row = df_plot.iloc[0]\n",
    "            runtime_df = compute_throughput_df(row[\"log\"], row[\"chunk_size_mb\"] * MB)\n",
    "            # remove rows where runtime_upload or runtime_download is less than 0.1s\n",
    "            with plt.style.context([\"seaborn-white\", {\"font.size\": 10}]):\n",
    "                # plot histogram of runtime_upload, runtime_download\n",
    "                # plot upload if mean upload time is greater than 0.1s\n",
    "                runtime_upload_filtered = runtime_df[runtime_df.runtime_upload > 0.1]\n",
    "                ax.hist(runtime_upload_filtered.runtime_upload, bins=50, label=\"upload\", alpha=0.5)\n",
    "                # plot download if mean download time is greater than 0.1s\n",
    "                runtime_download_filtered = runtime_df[runtime_df.runtime_download > 0.2]\n",
    "                ax.hist(runtime_df.runtime_download, bins=50, label=\"download\", alpha=0.5)\n",
    "                ax.legend()\n",
    "                ax.set_xlabel(\"runtime (s)\")\n",
    "                ax.set_xlim(0, 5.0)\n",
    "            pbar.update(1)\n",
    "\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / \"runtime_hist.png\", dpi=100, bbox_inches=\"tight\")\n",
    "fig.savefig(fig_dir / \"runtime_hist.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show upload_gbits and download_gbits distribution over all chunks over all hops\n",
    "df_throughput = compute_throughput_df(df.log.iloc[0], df.chunk_size_mb.iloc[0] * MB)\n",
    "with plt.style.context([\"seaborn-white\", {\"font.size\": 10}]):\n",
    "    # discard rows where runtime_upload or runtime_download is less than 0.1s\n",
    "    runtime_df = df_throughput.loc[(df_throughput.runtime_upload > 0.1) & (df_throughput.runtime_download > 0.1)]\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.hist(df_throughput.upload_gbits, bins=50, alpha=0.5, label=\"upload\")\n",
    "    ax.hist(df_throughput.download_gbits, bins=50, alpha=0.5, label=\"download\")\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(\"throughput (Gbps)\")\n",
    "    ax.set_xlim(0, 5.0)\n",
    "\n",
    "fig.patch.set_facecolor(\"white\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(fig_dir / \"throughput_hist.png\", dpi=100, bbox_inches=\"tight\")\n",
    "fig.savefig(fig_dir / \"throughput_hist.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_dir = fig_dir / \"bytes_complete_over_time\"\n",
    "sub_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# plot grid of subplots\n",
    "grouped = df.groupby([\"src_region\", \"dst_region\"])\n",
    "n_rows = len(grouped.groups)\n",
    "n_cols = max(len(grouped.get_group(group).inter_region.unique()) for group in grouped.groups)\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 4))\n",
    "with tqdm(total=n_rows * n_cols) as pbar:\n",
    "    for plot_row_idx, ((src_region, dst_region), df_row) in enumerate(grouped):\n",
    "        # set subplots row labels on left of plot\n",
    "        df_row[\"inter_region\"] = df_row.inter_region.fillna(\"Direct\")\n",
    "        transfer_bytes = df_row.chunk_size_mb.values[0] * MB\n",
    "        axs[plot_row_idx, 0].set_ylabel(f\"{src_region} => {dst_region}\")\n",
    "        for plot_col_idx, (inter_region, df_plot) in enumerate(df_row.groupby(\"inter_region\")):\n",
    "            if plot_row_idx == 0:\n",
    "                axs[plot_row_idx, plot_col_idx].set_title(f\"Relay: {inter_region}\")\n",
    "            ax = axs[plot_row_idx, plot_col_idx]\n",
    "            row = df_plot.iloc[0]\n",
    "            runtime_df = compute_throughput_df(row[\"log\"], row[\"chunk_size_mb\"] * MB).reset_index()\n",
    "            runtime_df = runtime_df[runtime_df[\"hop_idx\"] == max(runtime_df[\"hop_idx\"])]\n",
    "\n",
    "            # select ['upload_complete_time'] column\n",
    "            time_uploaded_df = (\n",
    "                runtime_df.loc[:, [\"upload_complete_time\"]]\n",
    "                .dropna()\n",
    "                .reset_index(drop=True)\n",
    "                .sort_values(by=\"upload_complete_time\")\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "            # bytes_uploaded = (idx + 1) * transfer_bytes\n",
    "            time_uploaded_df[\"bytes_uploaded\"] = (time_uploaded_df.index + 1) * transfer_bytes\n",
    "            if len(time_uploaded_df) > 0:\n",
    "                time_uploaded_df[\"upload_complete_time\"] = time_uploaded_df.upload_complete_time - min(\n",
    "                    time_uploaded_df.upload_complete_time\n",
    "                )\n",
    "                if max(time_uploaded_df.bytes_uploaded) > 1 * GB:\n",
    "                    with plt.style.context([\"seaborn-white\", {\"font.size\": 10}]):\n",
    "                        # plot upload_complete_time vs bytes_uploaded\n",
    "                        ax.plot(time_uploaded_df.upload_complete_time, time_uploaded_df.bytes_uploaded / GB, label=\"uploaded\")\n",
    "                        ax.set_xlabel(\"Time (s)\")\n",
    "                        if plot_col_idx == 0:\n",
    "                            ax.set_ylabel(f\"GB uploaded\\n{src_region} => {dst_region}\")\n",
    "                        else:\n",
    "                            ax.set_ylabel(f\"GB uploaded\")\n",
    "            pbar.update(1)\n",
    "# white background\n",
    "fig.patch.set_facecolor(\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e615813c5489b1590d5f8b2d596a39a5f3baf5ccbb6dde5ecf5546914cc6cb8b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
